# Data-Science-Capstone-Project

Background

Nexus Bank is a financial institution dedicated to delivering unparalleled banking services to her clients.
Her mission is to establish enduring relationships with the customers by providing tailored financial solutions that align with individual needs and goals.
Nexus Bank offers a wide spectrum of banking solutions to accommodate customer lifestyle, including term deposits, personal
loans, and mortgage financing. Nexus team of seasoned banking professionals is committed to providing the utmost level of service, transparency, and honesty.

Problem statement

Poor term deposit in the bank
Nexux bank has conducted campaigns with the goal of acquiring deposits but haven't succedded.

Methodology

The methodology used in this case study involves the following steps:
Data cleaning and preprocessing: The first step is to clean and preprocess the data, including handling missing values,
removing outliers, and transforming variables as necessary.

Exploratory data analysis: Next, we will perform exploratory data analysis to gain insights into the data, such as identifying trends and patterns, and identifying correlations between variables.

Feature engineering: Based on the insights gained from the exploratory data analysis, feature engineering was performed to select the most relevant features for predicting customers who defaulted and those most likely to subscribe to term-deposit and transform them as necessary.

Encode categorical variables: Here the categorical variables are converted into numerical representations that machine learning algorithms can process. Common encoding techniques used in this project is one-hot encoding.

Data Spliting: The dataset was divided into training and testing sets to evaluate the model's performance on unseen data.

Scale/Normalize numerical variables: I scaled/normalized the numerical variables in the dataset to ensure they are on a similar scale. This step helps prevent features with larger magnitudes from dominating the model training process. I used the normalization (scaling to a specific range) technique.

Train the model: The machine learning model was fit into the training data.

Model selection and training: We will then select a suitable machine learning algorithm for predicting heart diseases, such as logistic regression, a decision tree, and other model will be trained on the preprocessed data.

Evaluate the model: I used the testing data to assess the model's performance, such as calculating accuracy, precision, recall, or other evaluation metrics.

The best model will be selected and recmmended for use.
